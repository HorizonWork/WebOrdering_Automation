"""
ViT5 Planner - Vietnamese Action Generation
Uses VietAI/vit5-base for generating action sequences
Encoder-Decoder architecture (like T5) for text-to-text tasks
"""

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig
from typing import List, Dict, Optional, Union
import json
from dataclasses import dataclass
from pathlib import Path
import yaml

from config.settings import settings
from src.utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class Action:
    """Action data structure"""
    skill: str
    params: Dict[str, any]
    confidence: float = 0.8
    reason: str = ""
    
    def to_dict(self) -> Dict:
        """Convert to dictionary"""
        return {
            'skill': self.skill,
            'params': self.params,
            'confidence': self.confidence,
            'reason': self.reason
        }


class ViT5Planner:
    """
    ViT5 wrapper for Vietnamese action planning and generation.
    
    **Architecture**: Encoder-Decoder (like T5)
    **Model**: VietAI/vit5-base (310M parameters)
    **Use Cases**:
        - Generate action sequences from observations
        - Multi-step workflow planning
        - ReAct reasoning (Thought â†’ Action)
        - Domain adaptation via LoRA fine-tuning
    
    **NOT for**:
        - Text embedding (use PhoBERT instead)
    
    **Performance**:
        - Inference: ~2 seconds per action (GPU)
        - Fine-tuning: 7-8 hours with LoRA (V100/A100)
    """
    
    def __init__(
        self,
        model_name: Optional[str] = None,
        device: Optional[str] = None,
        cache_dir: Optional[str] = None
    ):
        """
        Initialize ViT5 planner.
        
        Args:
            model_name: ViT5 model identifier (default: VietAI/vit5-base)
            device: cuda/cpu/mps
            cache_dir: Model cache directory
        """
        # Load config from YAML
        config_path = Path("config/models.yaml")
        if config_path.exists():
            with open(config_path) as f:
                config = yaml.safe_load(f)
                vit5_config = config.get('vit5', {})
        else:
            vit5_config = {}
        
        # Settings
        self.model_name = model_name or vit5_config.get('model_name', 'VietAI/vit5-base')
        self.device = device or settings.device
        self.max_input_length = vit5_config.get('max_input_length', 512)
        self.max_output_length = vit5_config.get('max_output_length', 256)
        self.num_beams = vit5_config.get('num_beams', 4)
        self.temperature = vit5_config.get('temperature', 0.7)
        self.top_p = vit5_config.get('top_p', 0.9)
        self.cache_dir = cache_dir or vit5_config.get('cache_dir', './checkpoints/vit5')
        
        logger.info(f"ğŸš€ Loading ViT5 from {self.model_name}")
        logger.info(f"ğŸ“ Device: {self.device}")
        logger.info(f"ğŸ“ Input max length: {self.max_input_length}")
        logger.info(f"ğŸ“ Output max length: {self.max_output_length}")
        
        # Load tokenizer
        logger.info("Loading tokenizer...")
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            cache_dir=self.cache_dir
        )
        logger.info("âœ“ Tokenizer loaded")
        
        # Load model
        logger.info("Loading model...")
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            self.model_name,
            cache_dir=self.cache_dir,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        ).to(self.device)
        self.model.eval()
        logger.info("âœ“ Model loaded")
        
        # Generation config
        self.generation_config = GenerationConfig(
            max_length=self.max_output_length,
            num_beams=self.num_beams,
            temperature=self.temperature,
            top_p=self.top_p,
            do_sample=True,
            early_stopping=True
        )
        
        # Print model info
        total_params = sum(p.numel() for p in self.model.parameters())
        logger.info(f"âœ… ViT5 ready! Parameters: {total_params:,} ({total_params/1e6:.1f}M)")
    
    @torch.no_grad()
    def generate(
        self,
        prompt: str,
        max_length: Optional[int] = None,
        num_beams: Optional[int] = None,
        temperature: Optional[float] = None,
        top_p: Optional[float] = None
    ) -> str:
        """
        Generate text from prompt.
        
        Args:
            prompt: Input prompt in Vietnamese
            max_length: Override max output length
            num_beams: Override beam search width
            temperature: Override sampling temperature
            top_p: Override nucleus sampling
            
        Returns:
            Generated text
            
        Example:
            >>> planner = ViT5Planner()
            >>> output = planner.generate("Nhiá»‡m vá»¥: TÃ¬m Ã¡o khoÃ¡c")
            >>> print(output)
        """
        # Tokenize input
        inputs = self.tokenizer(
            prompt,
            max_length=self.max_input_length,
            truncation=True,
            return_tensors="pt"
        ).to(self.device)
        
        # Create generation config
        gen_config = GenerationConfig(
            max_length=max_length or self.max_output_length,
            num_beams=num_beams or self.num_beams,
            temperature=temperature or self.temperature,
            top_p=top_p or self.top_p,
            do_sample=True,
            early_stopping=True
        )
        
        # Generate
        outputs = self.model.generate(
            **inputs,
            generation_config=gen_config
        )
        
        # Decode
        generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        return generated
    
    def generate_thought(
        self,
        query: str,
        observation: Dict,
        history: Optional[List[Dict]] = None
    ) -> str:
        """
        Generate reasoning thought (ReAct pattern).
        
        Args:
            query: Original user query
            observation: Current observation {url, dom, elements}
            history: Previous steps
            
        Returns:
            Thought/reasoning text
            
        Example:
            >>> thought = planner.generate_thought(
            ...     query="TÃ¬m Ã¡o khoÃ¡c",
            ...     observation={'url': 'shopee.vn', 'dom': '...'},
            ...     history=[]
            ... )
            >>> print(thought)
            "Cáº§n tÃ¬m kiáº¿m sáº£n pháº©m trÃªn Shopee"
        """
        # Build context
        context = f"ğŸ¯ Nhiá»‡m vá»¥: {query}\n\n"
        
        # Add history (last 3 steps to keep context manageable)
        if history:
            context += "ğŸ“œ Lá»‹ch sá»­ hÃ nh Ä‘á»™ng:\n"
            for i, step in enumerate(history[-3:], 1):
                thought = step.get('thought', '')
                action = step.get('action', {})
                obs_summary = str(step.get('observation', ''))[:100]
                
                context += f"{i}. ğŸ’­ Suy nghÄ©: {thought}\n"
                context += f"   âš¡ HÃ nh Ä‘á»™ng: {action.get('skill', '')}({action.get('params', {})})\n"
                context += f"   ğŸ‘ï¸  Quan sÃ¡t: {obs_summary}...\n\n"
        
        # Add current observation
        dom_snippet = observation.get('dom', '')[:400]  # Truncate DOM
        url = observation.get('url', '')
        elements = observation.get('elements', [])
        
        context += f"ğŸŒ Tráº¡ng thÃ¡i hiá»‡n táº¡i:\n"
        context += f"  â€¢ URL: {url}\n"
        context += f"  â€¢ DOM: {dom_snippet}...\n"
        context += f"  â€¢ Sá»‘ pháº§n tá»­ tÆ°Æ¡ng tÃ¡c: {len(elements)}\n\n"
        context += "ğŸ’¡ HÃ£y suy nghÄ© xem bÆ°á»›c tiáº¿p theo cáº§n lÃ m gÃ¬:"
        
        # Generate thought
        thought = self.generate(
            context,
            max_length=128,
            num_beams=4,
            temperature=0.8
        )
        
        logger.debug(f"ğŸ’­ Thought: {thought}")
        return thought
    
    def generate_action(
        self,
        thought: str,
        observation: Dict,
        available_skills: Optional[List[str]] = None
    ) -> Dict:
        """
        Generate next action from thought and observation.
        
        Args:
            thought: Current reasoning/thought
            observation: Current state observation
            available_skills: List of available skill names
            
        Returns:
            Action dictionary: {skill, params, confidence, reason}
            
        Example:
            >>> action = planner.generate_action(
            ...     thought="Cáº§n click vÃ o search box",
            ...     observation={'dom': '...'},
            ...     available_skills=['goto', 'click', 'type']
            ... )
            >>> print(action)
            {'skill': 'click', 'params': {'selector': '#search'}, ...}
        """
        if available_skills is None:
            available_skills = [
                'goto', 'click', 'type', 'select', 'scroll', 
                'wait_for', 'screenshot', 'complete'
            ]
        
        # Get observation details
        dom = observation.get('dom', '')[:600]
        elements = observation.get('elements', [])[:10]  # Top 10
        url = observation.get('url', '')
        
        # Format interactive elements
        elements_str = ""
        for elem in elements:
            selector = elem.get('selector', '')
            text = elem.get('text', '')[:50]
            tag = elem.get('tag', '')
            elements_str += f"  â€¢ {selector} ({tag}): \"{text}\"\n"
        
        # Build prompt
        prompt = f"""Dá»±a trÃªn tÃ¬nh huá»‘ng, hÃ£y quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng tiáº¿p theo.

ğŸ’­ Suy nghÄ©: {thought}

ğŸ› ï¸  Ká»¹ nÄƒng cÃ³ sáºµn: {', '.join(available_skills)}

ğŸŒ URL hiá»‡n táº¡i: {url}

ğŸ“„ Tráº¡ng thÃ¡i DOM:
{dom}

ğŸ”˜ CÃ¡c pháº§n tá»­ tÆ°Æ¡ng tÃ¡c:
{elements_str}

Tráº£ lá»i theo Ä‘á»‹nh dáº¡ng JSON:
{{
  "skill": "tÃªn_ká»¹_nÄƒng",
  "params": {{"param1": "value1", "param2": "value2"}},
  "reason": "giáº£i thÃ­ch ngáº¯n gá»n"
}}

HÃ nh Ä‘á»™ng:"""
        
        # Generate action JSON
        action_json = self.generate(
            prompt,
            max_length=256,
            num_beams=1,  # Greedy for consistency
            temperature=0.3  # Low temp for deterministic output
        )
        
        # Parse JSON
        try:
            # Clean markdown formatting if present
            if "```
                action_json = action_json.split("```json").split("```
            elif "```" in action_json:
                action_json = action_json.split("``````")[0]
            
            action = json.loads(action_json.strip())
            
            # Validate skill
            if action.get('skill') not in available_skills:
                logger.warning(f"âš ï¸  Invalid skill: {action.get('skill')}, defaulting to 'wait_for'")
                action['skill'] = 'wait_for'
                action['params'] = {'selector': 'body'}
            
            # Ensure params is dict
            if not isinstance(action.get('params'), dict):
                action['params'] = {}
            
            # Add confidence
            action['confidence'] = 0.85
            
        except (json.JSONDecodeError, KeyError, Exception) as e:
            logger.error(f"âŒ Failed to parse action JSON: {e}")
            logger.error(f"Raw output: {action_json}")
            
            # Fallback action
            action = {
                'skill': 'wait_for',
                'params': {'selector': 'body'},
                'reason': f'JSON parse error: {str(e)}',
                'confidence': 0.3
            }
        
        logger.debug(f"âš¡ Action: {action['skill']}({action['params']})")
        return action
    
    def generate_plan(
        self,
        query: str,
        context: Optional[Dict] = None
    ) -> str:
        """
        Generate high-level multi-step plan from query.
        
        Args:
            query: User query in Vietnamese
            context: Additional context (url, dom, etc.)
            
        Returns:
            Plan as text with numbered steps
            
        Example:
            >>> plan = planner.generate_plan("Mua Ã¡o khoÃ¡c trÃªn Shopee")
            >>> print(plan)
            1. VÃ o trang Shopee
            2. TÃ¬m kiáº¿m "Ã¡o khoÃ¡c"
            3. Lá»c káº¿t quáº£...
        """
        prompt = f"ğŸ¯ Nhiá»‡m vá»¥: {query}\n\n"
        
        if context:
            if 'url' in context:
                prompt += f"ğŸŒ Trang web: {context['url']}\n"
            if 'constraints' in context:
                prompt += f"âš ï¸  Äiá»u kiá»‡n: {context['constraints']}\n"
        
        prompt += "\nğŸ“‹ HÃ£y láº­p káº¿ hoáº¡ch chi tiáº¿t tá»«ng bÆ°á»›c Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥:"
        
        plan = self.generate(
            prompt,
            max_length=512,
            num_beams=4,
            temperature=0.7
        )
        
        logger.debug(f"ğŸ“‹ Plan generated: {len(plan)} chars")
        return plan
    
    def explain_action(
        self,
        action: Dict,
        result: Dict
    ) -> str:
        """
        Generate explanation for why action was taken and its result.
        
        Args:
            action: Action that was executed
            result: Result of the action
            
        Returns:
            Explanation text
        """
        prompt = f"""HÃ nh Ä‘á»™ng Ä‘Ã£ thá»±c hiá»‡n:
Ká»¹ nÄƒng: {action.get('skill')}
Tham sá»‘: {action.get('params')}

Káº¿t quáº£:
Tráº¡ng thÃ¡i: {result.get('status')}
ThÃ´ng Ä‘iá»‡p: {result.get('message')}

Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao hÃ nh Ä‘á»™ng nÃ y Ä‘Æ°á»£c chá»n vÃ  káº¿t quáº£ cá»§a nÃ³:"""
        
        explanation = self.generate(
            prompt,
            max_length=128,
            temperature=0.7
        )
        
        return explanation


# Test & Usage Examples
if __name__ == "__main__":
    print("=" * 70)
    print("ViT5 Planner - Test & Examples")
    print("=" * 70 + "\n")
    
    # Initialize planner
    planner = ViT5Planner()
    
    # Mock observation
    observation = {
        'url': 'https://shopee.vn',
        'dom': '<div class="search-container"><input id="search-box" placeholder="TÃ¬m kiáº¿m"/><button id="search-btn">TÃ¬m</button></div>',
        'elements': [
            {'selector': '#search-box', 'tag': 'input', 'text': '', 'attributes': {'placeholder': 'TÃ¬m kiáº¿m'}},
            {'selector': '#search-btn', 'tag': 'button', 'text': 'TÃ¬m', 'attributes': {}},
            {'selector': '.category-link', 'tag': 'a', 'text': 'Thá»i trang nam', 'attributes': {'href': '/fashion'}}
        ]
    }
    
    # Test 1: Generate Thought
    print("=" * 70)
    print("Test 1: Generate Thought (ReAct Pattern)")
    print("=" * 70)
    query = "TÃ¬m Ã¡o khoÃ¡c nam mÃ u Ä‘en giÃ¡ dÆ°á»›i 500k"
    thought = planner.generate_thought(
        query=query,
        observation=observation,
        history=[]
    )
    print(f"\nğŸ¯ Query: {query}")
    print(f"ğŸ’­ Thought: {thought}\n")
    
    # Test 2: Generate Action
    print("=" * 70)
    print("Test 2: Generate Action")
    print("=" * 70)
    action = planner.generate_action(
        thought=thought,
        observation=observation,
        available_skills=['goto', 'click', 'type', 'select', 'complete']
    )
    print(f"\nğŸ’­ Thought: {thought}")
    print(f"âš¡ Action: {json.dumps(action, ensure_ascii=False, indent=2)}\n")
    
    # Test 3: Generate Plan
    print("=" * 70)
    print("Test 3: Generate High-Level Plan")
    print("=" * 70)
    plan = planner.generate_plan(
        query="Mua Ã¡o khoÃ¡c trÃªn Shopee vá»›i giÃ¡ tá»‘t nháº¥t",
        context={'url': 'https://shopee.vn'}
    )
    print(f"\nğŸ¯ Query: Mua Ã¡o khoÃ¡c trÃªn Shopee vá»›i giÃ¡ tá»‘t nháº¥t")
    print(f"ğŸ“‹ Plan:\n{plan}\n")
    
    # Test 4: Explain Action
    print("=" * 70)
    print("Test 4: Explain Action Result")
    print("=" * 70)
    mock_action = {'skill': 'click', 'params': {'selector': '#search-box'}}
    mock_result = {'status': 'success', 'message': 'Search box focused'}
    explanation = planner.explain_action(mock_action, mock_result)
    print(f"\nâš¡ Action: click(#search-box)")
    print(f"âœ… Result: success")
    print(f"ğŸ’¡ Explanation: {explanation}\n")
    
    print("=" * 70)
    print("âœ… All tests completed!")
    print("=" * 70)
